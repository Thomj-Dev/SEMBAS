{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook walks through some basic analysis of the SEMBAS results. Specifically,\n",
    "it is used for determining which model's output can be trusted, and therefore improve\n",
    "reducing the ensemble's error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "import json\n",
    "import os\n",
    "\n",
    "from rtree.index import Index, Property\n",
    "\n",
    "from numpy import ndarray\n",
    "\n",
    "from network import *\n",
    "from data import FutData, f as fut\n",
    "from main import classify_validity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup\n",
    "Specify the paths you chose for your models. Note: this will be relative to where\n",
    "this notebook is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BOUNDARY_PATH = \"../../../.data/boundaries\"\n",
    "MODEL_PATH = \"../../../.models/bnn_expl\" # Same loc as --model-path arg\n",
    "\n",
    "\n",
    "NETWORK_PATH = f\"{MODEL_PATH}/ensemble/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_boundary(i: int) -> ndarray:\n",
    "    with open(f\"{BOUNDARY_PATH}/boundary_2_{i}.json\") as f: # TODO\n",
    "        data = json.load(f)\n",
    "    return np.array(data[\"boundary_points\"]), np.array(data[\"boundary_surface\"])\n",
    "\n",
    "\n",
    "def load_boundary_into_rtree(bpoints: ndarray, surface) -> Index:\n",
    "    p = Property()\n",
    "    p.set_dimension(bpoints.shape[1])\n",
    "    \n",
    "    index = Index(properties=p)\n",
    "    for i, (b, n) in enumerate(zip(bpoints, surface)):\n",
    "        index.insert(i, b, (b, n))\n",
    "        \n",
    "    return index\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pred_perf(p: ndarray, index: Index) -> tuple[bool, float]:\n",
    "    \"Predicts the performance mode of @p given RTree @index\"\n",
    "    b, n = next(index.nearest(p, 1, 'raw'))\n",
    "    \n",
    "    s = p - b\n",
    "    dist = np.linalg.norm(s)\n",
    "    v: ndarray = s / dist\n",
    "    \n",
    "    return v.dot(n) < 0.0, dist\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Specifying SEMBAS Selected Models\n",
    "The main.rs generates boundary data, but also provides a list of indices to the\n",
    "models that are redundant (i.e. the \"skip-list\"). This skip-list can be used to trim\n",
    "down the number of necessary models to produce a reasonable ensemble.\n",
    "\n",
    "These tools are both early in development and mostly act as a proof-of-concept, so\n",
    "optimization is necessary to get it performing well enough to be viable.\n",
    "\n",
    "Below is the skip_list for the notebook, paste in the indices that were skipped,\n",
    "which can be found in the main.rs standard output at the end of exploring the models.\n",
    "Alternatively, leave it empty or specify which models you wish to skip manually (or\n",
    "edit the model_indices, which specifies which models to include in the ensemble\n",
    "directly)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "skip_list = [] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "found 1000 number of models\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../../.data/boundaries/boundary_2_1.json'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 15\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m network\n\u001b[0;32m     13\u001b[0m dataset \u001b[38;5;241m=\u001b[39m FutData(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m12\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m boundary_rtrees \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[43mload_boundary_into_rtree\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mload_boundary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmodel_indices\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     16\u001b[0m networks \u001b[38;5;241m=\u001b[39m [load(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m model_indices]\n\u001b[0;32m     17\u001b[0m all_networks \u001b[38;5;241m=\u001b[39m [load(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m)]\n",
      "Cell \u001b[1;32mIn[6], line 15\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m network\n\u001b[0;32m     13\u001b[0m dataset \u001b[38;5;241m=\u001b[39m FutData(\u001b[38;5;241m2\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m12\u001b[39m)\n\u001b[1;32m---> 15\u001b[0m boundary_rtrees \u001b[38;5;241m=\u001b[39m [load_boundary_into_rtree(\u001b[38;5;241m*\u001b[39m\u001b[43mload_boundary\u001b[49m\u001b[43m(\u001b[49m\u001b[43mi\u001b[49m\u001b[43m)\u001b[49m) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m model_indices]\n\u001b[0;32m     16\u001b[0m networks \u001b[38;5;241m=\u001b[39m [load(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m model_indices]\n\u001b[0;32m     17\u001b[0m all_networks \u001b[38;5;241m=\u001b[39m [load(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1000\u001b[39m)]\n",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m, in \u001b[0;36mload_boundary\u001b[1;34m(i)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_boundary\u001b[39m(i: \u001b[38;5;28mint\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m ndarray:\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mBOUNDARY_PATH\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/boundary_2_\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mi\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.json\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f: \u001b[38;5;66;03m# TODO\u001b[39;00m\n\u001b[0;32m      3\u001b[0m         data \u001b[38;5;241m=\u001b[39m json\u001b[38;5;241m.\u001b[39mload(f)\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39marray(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboundary_points\u001b[39m\u001b[38;5;124m\"\u001b[39m]), np\u001b[38;5;241m.\u001b[39marray(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mboundary_surface\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32mc:\\Users\\johnt\\Documents\\Projects\\sembas\\.venv\\Lib\\site-packages\\IPython\\core\\interactiveshell.py:324\u001b[0m, in \u001b[0;36m_modified_open\u001b[1;34m(file, *args, **kwargs)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m file \u001b[38;5;129;01min\u001b[39;00m {\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m}:\n\u001b[0;32m    318\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    319\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIPython won\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt let you open fd=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfile\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m by default \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    320\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mas it is likely to crash IPython. If you know what you are doing, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    321\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124myou can use builtins\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m open.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    322\u001b[0m     )\n\u001b[1;32m--> 324\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio_open\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../../.data/boundaries/boundary_2_1.json'"
     ]
    }
   ],
   "source": [
    "total_models = len(os.listdir(NETWORK_PATH))\n",
    "print(f\"found {total_models} number of models\")\n",
    "\n",
    "model_indices = [x for x in range(total_models) if x not in skip_list]\n",
    "\n",
    "\n",
    "def load(i: int) -> nn.Module:\n",
    "    network = nn.Sequential(ConcreteLinear(2, 50), nn.ReLU(), ConcreteLinear(50, 1))\n",
    "    state = torch.load(f\"{NETWORK_PATH}/network_{i}.model\")\n",
    "    network.load_state_dict(state)\n",
    "    return network\n",
    "\n",
    "dataset = FutData(2**12)\n",
    "\n",
    "boundary_rtrees = [load_boundary_into_rtree(*load_boundary(i)) for i in model_indices]\n",
    "networks = [load(i) for i in model_indices]\n",
    "all_networks = [load(i) for i in range(1000)]\n",
    "\n",
    "# Doesn't use the boundary data, but only uses the mean of the model results\n",
    "# (traditional solution)\n",
    "ensemble_mean = lambda x: np.array([model(x).detach() for model in networks]).mean()\n",
    "\n",
    "# Similar to ensemble_mean, but instead of using the SEMBAS selected models it uses\n",
    "# all of them.\n",
    "full_ensemble_mean = lambda x: np.array([model(x).detach() for model in all_networks]).mean()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ensemble_sembas_model(x):\n",
    "    \"\"\"\n",
    "    Ensemble model that applies SEMBAS boundary data for determining which model's\n",
    "    output can be trusted the most.\n",
    "    \"\"\"\n",
    "    result = np.zeros((x.shape[0], 1))\n",
    "    \n",
    "    for i, xi in enumerate(x):\n",
    "        goodboys = []\n",
    "        min_boy = None\n",
    "        k = 0\n",
    "        for tree, model in zip(boundary_rtrees, networks):\n",
    "            sembas_p = dataset.inverse_transform_request(xi).detach().numpy()\n",
    "            cls, dist = pred_perf(sembas_p, tree)\n",
    "            if cls:\n",
    "                goodboys.append(model)\n",
    "            \n",
    "            if min_boy is None or dist < min_boy[1]:\n",
    "                min_boy = (model, dist)\n",
    "            \n",
    "            k += 1\n",
    "        \n",
    "        xi = xi.reshape(1, -1)\n",
    "        if len(goodboys) == 0:\n",
    "            result[i] = min_boy[0](xi).detach()\n",
    "        else:\n",
    "            y_hat = np.array([gb(xi).detach().item() for gb in goodboys])\n",
    "            result[i] = y_hat.mean()\n",
    "            \n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_random_ensemble(n: int):\n",
    "    \"\"\"\n",
    "    Generates an ensemble model from a random sub-population of models.\n",
    "    @n is the number of models to include.\n",
    "    \"\"\"\n",
    "    rng = np.random.default_rng()\n",
    "    rand_net = []\n",
    "    picks = rng.choice(np.arange(total_models), n, replace=False)#np.random.randint(0, 100, len(skip_list))\n",
    "    for i in [x for x in picks]:\n",
    "        rand_net.append(load(i))\n",
    "    return lambda x: np.median([model(x).detach() for model in rand_net])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, dataset: FutData):\n",
    "    \"Returns the MSE of the model over the @dataset\"\n",
    "    x, y = dataset\n",
    "    pred = model(x).squeeze()\n",
    "    \n",
    "    err:ndarray = y - pred\n",
    "    return (np.power(err, 2.0)).mean()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "x, y = dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluating\n",
    "First, we show the average performance of a randomly selected ensemble, followed by\n",
    "the sembas-selected ensemble performance using the mean of the outputs, ending with \n",
    "the same ensemble with sembas boundary data for selecting trusted outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johnt\\AppData\\Local\\Temp\\ipykernel_34652\\3603405742.py:6: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state = torch.load(f\"../../../.models/bnn_expl/ensemble/network_{i}.model\")\n",
      "C:\\Users\\johnt\\AppData\\Local\\Temp\\ipykernel_34652\\3901141962.py:9: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  return (np.power(err, 2.0)).mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Err: torch.Size([65536, 1]) tensor(0.5358) tensor(0.0002)\n",
      "Err: torch.Size([65536, 1]) tensor(2.7954) tensor(4.0919e-05)\n",
      "Err: torch.Size([65536, 1]) tensor(3.3301) tensor(1.5423e-05)\n",
      "Err: torch.Size([65536, 1]) tensor(4.5047) tensor(0.0002)\n",
      "Err: torch.Size([65536, 1]) tensor(2.5315) tensor(7.6294e-06)\n",
      "Err: torch.Size([65536, 1]) tensor(1.0921) tensor(0.0006)\n",
      "Err: torch.Size([65536, 1]) tensor(3.0504) tensor(2.1726e-05)\n",
      "Err: torch.Size([65536, 1]) tensor(0.9272) tensor(5.9128e-05)\n",
      "Err: torch.Size([65536, 1]) tensor(2.5032) tensor(4.0710e-05)\n",
      "Err: torch.Size([65536, 1]) tensor(3.0750) tensor(0.0001)\n",
      "Err: torch.Size([65536, 1]) tensor(3.9759) tensor(2.8372e-05)\n",
      "Err: torch.Size([65536, 1]) tensor(1.1206) tensor(0.0002)\n",
      "Err: torch.Size([65536, 1]) tensor(1.8088) tensor(6.4373e-06)\n",
      "Err: torch.Size([65536, 1]) tensor(1.9684) tensor(1.3828e-05)\n",
      "Err: torch.Size([65536, 1]) tensor(0.4936) tensor(0.0001)\n",
      "Err: torch.Size([65536, 1]) tensor(3.5785) tensor(4.0561e-05)\n",
      "Err: torch.Size([65536, 1]) tensor(1.4292) tensor(0.0002)\n",
      "Err: torch.Size([65536, 1]) tensor(2.3994) tensor(8.7738e-05)\n",
      "Err: torch.Size([65536, 1]) tensor(0.8234) tensor(2.5749e-05)\n",
      "Err: torch.Size([65536, 1]) tensor(2.5232) tensor(1.5140e-05)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "np.float64(3.0610135078430174)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([test(create_random_ensemble(len(model_indices)), dataset).item() for i in range(20)]).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Err: torch.Size([65536, 1]) tensor(3.5204) tensor(2.6405e-05)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johnt\\AppData\\Local\\Temp\\ipykernel_34652\\3901141962.py:9: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  return (np.power(err, 2.0)).mean()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(1.1855)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test(ensemble_mean, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johnt\\AppData\\Local\\Temp\\ipykernel_34652\\3603405742.py:44: DeprecationWarning: __array__ implementation doesn't accept a copy keyword, so passing copy=False failed. __array__ must implement 'dtype' and 'copy' keyword arguments.\n",
      "  result[i] = min_boy[0](xi).detach()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "In mode: (65536,) [0. 0. 0. ... 0. 0. 1.]\n",
      "Err torch.Size([65536]) tensor(-0.1027, dtype=torch.float64) tensor(-2.7588, dtype=torch.float64) tensor(4.8490, dtype=torch.float64)\n",
      "Err mse torch.Size([65536])\n",
      "Truth, pred torch.Size([65536, 1]) (65536, 1)\n",
      "Percent in mode: 0.7654571533203125\n",
      "In mode accuracy: tensor(0.1792, dtype=torch.float64)\n",
      "Out of mode accuracy: tensor(1.1620, dtype=torch.float64)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\johnt\\AppData\\Local\\Temp\\ipykernel_34652\\3901141962.py:18: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  err = y.squeeze() - pred.squeeze()\n",
      "C:\\Users\\johnt\\AppData\\Local\\Temp\\ipykernel_34652\\3901141962.py:22: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  print(\"Err mse\", np.power(err, 2.0).shape)\n",
      "C:\\Users\\johnt\\AppData\\Local\\Temp\\ipykernel_34652\\3901141962.py:25: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  print(\"In mode accuracy:\", np.power(err[in_mode == 1], 2.0).mean())\n",
      "C:\\Users\\johnt\\AppData\\Local\\Temp\\ipykernel_34652\\3901141962.py:26: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  print(\"Out of mode accuracy:\", np.power(err[in_mode == 0], 2).mean())\n",
      "C:\\Users\\johnt\\AppData\\Local\\Temp\\ipykernel_34652\\3901141962.py:28: DeprecationWarning: __array_wrap__ must accept context and return_scalar arguments (positionally) in the future. (Deprecated NumPy 2.0)\n",
      "  return (np.power(err, 2.0)).mean()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(0.4097, dtype=torch.float64)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# testing performance\n",
    "\n",
    "test(ensemble_sembas_model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from data import f as fut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "model_i = model_indices[i]\n",
    "ensemble = create_random_ensemble(1000)\n",
    "model = lambda x: torch.tensor(ensemble(x), dtype=torch.float64)\n",
    "bpoints, surface = load_boundary(model_i)\n",
    "index = boundary_rtrees[i]\n",
    "\n",
    "fig, axes = plt.subplots(ncols=2)\n",
    "axl, axr = axes\n",
    "n = int(dataset.data_size**0.5)\n",
    "\n",
    "x, y = dataset\n",
    "\n",
    "pred, _ = ensemble_sembas_model(x)\n",
    "\n",
    "err: ndarray = y.squeeze() - pred.squeeze()\n",
    "y_cls = np.power(err, 2.0) < 0.5\n",
    "\n",
    "pred_rand = create_random_ensemble(len(model_indices))(x)\n",
    "err_rand: ndarray = y.squeeze() - pred_rand.squeeze()\n",
    "y_cls_rand = np.power(err_rand, 2.0) < 0.5\n",
    "\n",
    "\n",
    "axl.imshow(y_cls.reshape(n, n))\n",
    "axr.imshow(y_cls_rand.reshape(n, n))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
